{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f816faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler\n",
    "                                                                                                                                \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c60f3a",
   "metadata": {},
   "source": [
    "### 设置好device，以充分发挥GPU的计算优势，同时要兼容没有GPU的设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ebd7c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据和模型都要加载到正确的设备上，否则会因不兼容而报错\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "648b2fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\wordlib 文件夹存在，可以使用...\n"
     ]
    }
   ],
   "source": [
    "# 设置数据文件夹\n",
    "DATA_PATH = Path(\"data/\")\n",
    "IMAGE_PATH = DATA_PATH / \"wordlib\"    #\n",
    "IMAGE_PATH_LIST = list(IMAGE_PATH.glob(\"*.gif\"))  \n",
    "\n",
    "# 如果文件夹不存在，则创建一个... \n",
    "if IMAGE_PATH.is_dir():\n",
    "    print(f\"{IMAGE_PATH} 文件夹存在，可以使用...\")\n",
    "else:\n",
    "    print(f\"{IMAGE_PATH}文件平不存在，创建中...\")\n",
    "    IMAGE_PATH.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312298bf",
   "metadata": {},
   "source": [
    "### 准备数据，查找指定文件夹中包含哪些文字，并设置其classes和labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b95fc85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 查找指定文件夹中的classes\n",
    "def find_classes(directory: str,ext:str='gif') -> Tuple[List[str], Dict[str, int],List[str]]:\n",
    "    \"\"\"根据指定文件夹下的图片文件名的第一名字形成类别classes.\n",
    "    \n",
    "    书法图片文件命名规范为：字_字体_书法家_文件编号.gif，如：予_行书_鲜于枢_12046.gif.\n",
    "\n",
    "    Args:\n",
    "        directory (str): target directory to load distinct words from.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
    "    \n",
    "    Example:\n",
    "        data\\wordlib\\予_行书_鲜于枢_12046.gif 分割_前面的字符是书法对应的文字\n",
    "        >>> ([\"予\", \"大\",...], {\"予\": 203, ...})\n",
    "    \"\"\"\n",
    "    # 1. 扫描路径下全部文件，通过文件名首字符为图片所对应的汉字这样的命名规则，得到该路径下的全部汉字。\n",
    "    image_path_list = list(pathlib.Path(directory).glob(f\"*.{ext}\"))\n",
    "    image_classes_set = set()  #因为相同的字有多张图，所以使用set集合去重\n",
    "    images_classes_list=[]\n",
    "    images_name_list=[]\n",
    "    for  path in   image_path_list:\n",
    "        image_classes_set.add(path.name.split('_')[0])\n",
    "        images_name_list.append(path.name)\n",
    "    classes=sorted([word for word in image_classes_set])\n",
    "    \n",
    "    # 2. 如果文件不存在或没有按要求命名，则报错\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"{directory}路径下的文件可能不存在或没有按要求命名（文件命名规则为word_font_writer_number.gif)\")\n",
    "        \n",
    "    # 3. 创建汉字列表及包含其序号的dict\n",
    "    class_to_idx=dict()\n",
    "    for i,word in enumerate(classes):\n",
    "        class_to_idx[word]=i   \n",
    "\n",
    "    return classes, class_to_idx, images_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a9e683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##  是模型训练的基础数据，重要，不要改动\n",
    "images_classes_list,word_classes_dict,images_name_list=find_classes(IMAGE_PATH,'gif') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90971c24-6393-4e65-b4f6-9bde5ec85173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 查找指定文件夹中的writer_classes\n",
    "def find_writer_classes(directory: str,ext:str='gif') -> Tuple[List[str], Dict[str, int],List[str]]:\n",
    "    \"\"\"根据指定文件夹下的图片文件名的第一名字形成类别classes.\n",
    "    \n",
    "    书法图片文件命名规范为：字_字体_书法家_文件编号.gif，如：予_行书_鲜于枢_12046.gif.\n",
    "\n",
    "    Args:\n",
    "        directory (str): target directory to load distinct words from.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
    "    \n",
    "    Example:\n",
    "        data\\wordlib\\予_行书_鲜于枢_12046.gif 最后一个分割符_后面的字符是书法对应的作者writer\n",
    "        >>> ([\"鲜于枢\", \"王羲之\"], {\"王羲之\": 266, ...})\n",
    "    \"\"\"\n",
    "    # 1. 扫描路径下全部文件，通过文件名首字符为图片所对应的汉字这样的命名规则，得到该路径下的全部汉字。\n",
    "    image_path_list = list(pathlib.Path(directory).glob(f\"*.{ext}\"))\n",
    "    image_writer_classes_set = set()  #因为相同的字有多张图，所以使用set集合去重\n",
    "    images_writer_classes_list=[]\n",
    "    images_writer_name_list=[]\n",
    "    for  path in   image_path_list:\n",
    "        image_writer_classes_set.add(path.name.split('_')[2])\n",
    "        images_writer_name_list.append(path.name)\n",
    "    writer_classes=sorted([word for word in image_writer_classes_set])\n",
    "    \n",
    "    # 2. 如果文件不存在或没有按要求命名，则报错\n",
    "    if not writer_classes:\n",
    "        raise FileNotFoundError(f\"{directory}路径下的文件可能不存在或没有按要求命名（文件命名规则为word_font_writer_number.gif)\")\n",
    "        \n",
    "    # 3. 创建汉字列表及包含其序号的dict\n",
    "    writer_class_to_idx=dict()\n",
    "    for i,word in enumerate(writer_classes):\n",
    "        writer_class_to_idx[word]=i   \n",
    "\n",
    "    return writer_classes, writer_class_to_idx, images_writer_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417b4ff1-a3df-49de-9f5e-a2d6bbae76b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##  是模型训练的基础数据，重要，不要改动\n",
    "images_writer_classes_list,word_writer_classes_dict,images_writer_name_list=find_writer_classes(IMAGE_PATH,'gif') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747734a",
   "metadata": {},
   "source": [
    "### 根据指定文件夹下的图片，生成文字列表，并以Dict保存每个文字的编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c70aaff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#以DataFrame形式保存字与Label的对应关系\n",
    "df_word_label_map=pd.DataFrame.from_dict(word_classes_dict,orient='index',columns=['label'])\n",
    "df_word_label_map.reset_index(inplace=True)\n",
    "df_word_label_map.columns=['word','label']\n",
    "#df_word_label_map.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04f332a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#以DataFrame形式保存字与Label的对应关系\n",
    "df_word_writer_label_map=pd.DataFrame.from_dict(word_writer_classes_dict,orient='index',columns=['label'])\n",
    "df_word_writer_label_map.reset_index(inplace=True)\n",
    "df_word_writer_label_map.columns=['word','label']\n",
    "#df_word_writer_label_map.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88e12c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 定义函数resolve_word_by_image_name，根据图片文件名找出对应的文字(class)、标签(Label)，并显示该文字图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562700a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resolve_word_by_image_name(image_path,word_classes_dict,show=True)->(str,str,Image):\n",
    "    \n",
    "    '''\n",
    "    定义函数 resolve_word_by_image_name，根据图片文件名找出对应的文字(class)、标签(Label)，并显示该文字图片\n",
    "    Args:\n",
    "        image_path (str): 文字图片路径和文件名.\n",
    "        word_classes_dict (dict): 文字及标签的字典\n",
    "        show (Boolean): 是否显示文字图片\n",
    "\n",
    "    Returns:\n",
    "        str,str: 文字class,文字label\n",
    "\n",
    "    Example:\n",
    "        data\\wordlib\\予_行书_鲜于枢_12046.gif \"_\"前面的字符是书法对应的文字\n",
    "        返回：\"予\",203\n",
    "    '''\n",
    "    image_class = Path(str(image_path)).name.split('_')[0]\n",
    "    image_label =word_classes_dict[image_class]\n",
    "    print(f'图片{image_path}对应的文字是：{image_class}, 其label为: {image_label}')\n",
    "    \n",
    "    \n",
    "    with Image.open(image_path).convert('RGB') as f: #    丁_草书_王铎_131029.gif data/wordlib/zxqsig.jpg\n",
    "        if show:\n",
    "            plt.figure(figsize=(2,2))\n",
    "            plt.imshow(f)  \n",
    "            plt.title(f\"图片size(H,W)为:({f.height}, {f.width})\",fontsize=16,fontproperties='Simhei')\n",
    "            plt.axis(False)            \n",
    "    return image_class,image_label,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ddc7ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片data\\wordlib\\主_行书_赵孟頫_11597.gif对应的文字是：主, 其label为: 32\n"
     ]
    }
   ],
   "source": [
    "random_image_path = random.choice(IMAGE_PATH_LIST)\n",
    "word,label,img=resolve_word_by_image_name(random_image_path,word_classes_dict,show=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c24e2d8",
   "metadata": {},
   "source": [
    "### 创建图片转换Transform，将图片按某种效果进行变换\n",
    "详见[Pytorch文档: ILLUSTRATION OF TRANSFORMS](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44490271-0fc0-464b-b5dd-011576860852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_word_writer_by_image_name(image_path,word_writer_classes_dict,show=True)->(str,str,Image):\n",
    "    \n",
    "    '''\n",
    "    定义函数 resolve_word_writer_by_image_name，根据图片文件名找出对应的文字作者(class)、标签(Label)，并显示该文字图片\n",
    "    Args:\n",
    "        image_path (str): 文字图片路径和文件名.\n",
    "        word_writer_classes_dict (dict): 文字及标签的字典\n",
    "        show (Boolean): 是否显示文字图片\n",
    "\n",
    "    Returns:\n",
    "        str,str: 作者class,文字作者label\n",
    "\n",
    "    Example:\n",
    "        data\\wordlib\\予_行书_鲜于枢_12046.gif \"_\"前面的字符是书法对应的文字\n",
    "        返回：\"鲜于枢\",203\n",
    "    '''\n",
    "    image_writer_class = Path(str(image_path)).name.split('_')[2]\n",
    "    image_writer_label =word_writer_classes_dict[image_writer_class]\n",
    "    print(f'图片{image_path}对应的文字是：{image_writer_class}, 其label为: {image_writer_label}')\n",
    "    \n",
    "    \n",
    "    with Image.open(image_path).convert('RGB') as f: #    丁_草书_王铎_131029.gif data/wordlib/zxqsig.jpg\n",
    "        if show:\n",
    "            plt.figure(figsize=(2,2))\n",
    "            plt.imshow(f)  \n",
    "            plt.title(f\"图片size(H,W)为:({f.height}, {f.width})\",fontsize=16,fontproperties='Simhei')\n",
    "            plt.axis(False)            \n",
    "    return image_writer_class,image_writer_label,f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bba2c77-e5e4-4c61-abef-3e20e1eee01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片data\\wordlib\\愛_行书_何绍基_28687.gif对应的文字是：何绍基, 其label为: 11\n"
     ]
    }
   ],
   "source": [
    "random_image_path = random.choice(IMAGE_PATH_LIST)\n",
    "word_writer,writer_label,img=resolve_word_writer_by_image_name(random_image_path,word_writer_classes_dict,show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4078feeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义 transform\n",
    "# 转换效果及使用方法详见：https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.Resize((370, 370)),\n",
    "    #transforms.TrivialAugmentWide(num_magnitude_bins=31,fill=255), # how intense \n",
    "    #transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "    transforms.RandomRotation(degrees=(-10, 10),expand=False,fill=255),\n",
    "    #transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.7, 0.9),fill=255),\n",
    "    #transforms.ElasticTransform(alpha=250.0,fill=255),\n",
    "    transforms.RandomPerspective(distortion_scale=0.1, p=0.2,fill=255),\n",
    "    transforms.ToTensor() # use ToTensor() last to get everything between 0 & 1\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a12d352c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_one_transformed_image(image_path,transform=None,save=True,save_path='data/augmented/'):\n",
    "    \n",
    "    '''\n",
    "    show_transformed_image，根据图片文件名和Transform，显示原图片和Transformed后的图片\n",
    "    Args:\n",
    "        image_path (str): 文字图片路径和文件名,如'data/wordlib/书_行书_王羲之_11946.gif'\n",
    "        transform (torchvision.transforms): 效果转换器\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    '''\n",
    "    with Image.open(image_path).convert('RGB') as f: # \n",
    "        fig, ax = plt.subplots(figsize=(4,2))\n",
    "        ax.axis(False)\n",
    "        ax = fig.add_subplot(1,2,1)\n",
    "        ax.imshow(f) \n",
    "        ax.set_title(f\"原图\\nSize: {f.size}\",fontsize=16,fontproperties='Simhei')\n",
    "        ax.axis(\"off\")     \n",
    "        ax = fig.add_subplot(1,2,2)\n",
    "        ax.axis(False)\n",
    "        if transform is not None:\n",
    "            transformed_image = transform(f).permute(1,2,0) #如果只想看某一个channel的话，再接上[:,:,0]\n",
    "            if transformed_image.shape[2]==1:\n",
    "                transformed_image=transformed_image.squeeze(2)\n",
    "            ax.imshow(transformed_image)\n",
    "            ax.set_title(f\"Transformed \\nSize: {transformed_image.shape}\",fontsize=16,fontproperties='Simhei')\n",
    "            #fig.suptitle(f\"{str(image_path).split('.')[0]}\",fontsize=16,fontproperties='Simhei')\n",
    "            \n",
    "            if save:\n",
    "                img=torchvision.transforms.ToPILImage()(transformed_image.permute(2,0,1))\n",
    "                img_name=str(image_path).split('/')[-1]\n",
    "                augmented_name=save_path+img_name.split('.')[0]+str(random.randint(100000,999999))+\"_aug.\"+img_name.split('.')[-1]\n",
    "                #print(augmented_name) #输出保存的文件名\n",
    "                img.save(augmented_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b40ac7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_one_transformed_image('data/wordlib/愛_行书_唐寅_28699.gif',aug_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "906ad0cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n=3, seed=None,show=True,save=True,save_path='data/augmented/'):\n",
    "    \"\"\"Plots a series of random images from image_paths.\n",
    "\n",
    "    Will open n image paths from image_paths, transform them\n",
    "    with transform and plot them side by side.\n",
    "\n",
    "    Args:\n",
    "        image_paths (list): List of target image paths. \n",
    "        transform (PyTorch Transforms): Transforms to apply to images.\n",
    "        n (int, optional): Number of images to plot. Defaults to 3.\n",
    "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
    "        save: save or not the transformed image file\n",
    "        save_path: where to save the transformed image file\n",
    "    \"\"\"\n",
    "    #random.seed(42)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        try:\n",
    "            with Image.open(image_path).convert('RGB') as f:\n",
    "                # 转换并显示图片\n",
    "                # Note: permute() 用于进行维度交换 \n",
    "                # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
    "                transformed_image = transform(f).permute(1, 2, 0) \n",
    "                if transformed_image.shape[2]==1:\n",
    "                    transformed_image=transformed_image.squeeze(2)\n",
    "                if save:\n",
    "                    img=torchvision.transforms.ToPILImage()(transformed_image.permute(2,0,1))\n",
    "                    filename=image_path.name.split('.')[0]+'_'+str(random.randint(100000,999999))+'_aug.'+image_path.name.split('.')[1]   \n",
    "                    #print(f'生成了新的增广变形文件{filename}')\n",
    "                    img.save(f'{save_path}/{filename}')\n",
    "\n",
    "                if show:\n",
    "                    fig, ax = plt.subplots(1, 2)\n",
    "                    ax[0].imshow(f) \n",
    "                    ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "                    ax[0].axis(\"off\")    \n",
    "\n",
    "                    ax[1].imshow(transformed_image)\n",
    "                    ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "                    ax[1].axis(\"off\")\n",
    "                    word_class=image_path.name.split('_')[0]\n",
    "                    fig.suptitle(f\"Class: {word_class}, label is :{word_classes_dict[word_class]}\", fontsize=16,fontproperties='Simhei')\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1913fd79",
   "metadata": {},
   "source": [
    "### 从已有的图片中增广生成新图片并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86de40a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_augmented_images(k=2,size=4,image_path_list=None,aug_transform=None,save=True,show=False,save_path='data/augmented/')->None:\n",
    "    \"\"\"\n",
    "    使用转换器随机生成增广图片并保存\n",
    "    生成图片数量为：k*size\n",
    "    \n",
    "    Args:\n",
    "        k=2:循环生成的次数\n",
    "        size=4：每次取样的大小\n",
    "        image_path_list=IMAGE_PATH_LIST：图片来源文件夹\n",
    "        aug_transform=None：转换器\n",
    "        save=True：是否保存到文件夹\n",
    "        show=False：是否显示生成的图片\n",
    "        save_path='data/augmented/'：文件保存路径\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(k):\n",
    "        plot_transformed_images(image_path_list, \n",
    "                            transform=aug_transform, \n",
    "                            n=size,save=True,show=False,save_path='data/augmented/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "193c007e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate_augmented_images(10,10,image_path_list=IMAGE_PATH_LIST,aug_transform=aug_transform) #从已有的图片中增广生成100张图片"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df82763",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 自定义继承自torch.utils.data.Dataset的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b9a2a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 自定义继承自torch.utils.data.Dataset的数据集\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. torch.utils.data.Dataset的子类\n",
    "class ImageFolderWordLibDataSet(Dataset):\n",
    "    \n",
    "    # 2. 用targ_dir和transform (可选)参数初始化\n",
    "    def __init__(self, targ_dir: str, transform = None, ext:str='gif'):\n",
    "              \n",
    "        # 3. 创建类属性\n",
    "        # 获取文件夹下所有的图片文件全名\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(f\"*.{ext}\")) # note: ext为文件扩展名，可以改为 .png's或.jpeg's\n",
    "        # 设置transforms\n",
    "        self.transform = transform\n",
    "        # 创建classes和class_to_idx属性\n",
    "        self.classes, self.class_to_idx,_ = find_classes(targ_dir,ext)\n",
    "\n",
    "    # 4. 定义加载图片的函数\n",
    "    def load_image(self, index: int):\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path).convert('RGB'),image_path\n",
    "    \n",
    "    # 5. 覆盖 the __len__()方法 \n",
    "    def __len__(self) -> int:\n",
    "        \"返回样本总数\"\n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. 覆盖 __getitem__() 方法(作为torch.utils.data.Dataset子类必须重写该方法)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"根据index返回一个样本的data and label (X, y).\"\n",
    "        img,img_path = self.load_image(index)\n",
    "        class_name  = img_path.name.split('_')[0] # 命名规则为: data_dir/word_font_writer_number.gif\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # 对图片作转换\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # 返回样本data, label (X, y)\n",
    "        else:\n",
    "            return img, class_idx # 返回样本 data, label (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e0e382d-5bb7-4641-a698-579a37dd7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义继承自torch.utils.data.Dataset的数据集\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. torch.utils.data.Dataset的子类\n",
    "class ImageWriterWordLibDataSet(Dataset):\n",
    "    \n",
    "    # 2. 用targ_dir和transform (可选)参数初始化\n",
    "    def __init__(self, targ_dir: str, transform = None, ext:str='gif'):\n",
    "              \n",
    "        # 3. 创建类属性\n",
    "        # 获取文件夹下所有的图片文件全名\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(f\"*.{ext}\")) # note: ext为文件扩展名，可以改为 .png's或.jpeg's\n",
    "        # 设置transforms\n",
    "        self.transform = transform\n",
    "        # 创建classes和class_to_idx属性\n",
    "        self.writer_classes, self.writer_class_to_idx,_ = find_writer_classes(targ_dir,ext)\n",
    "\n",
    "    # 4. 定义加载图片的函数\n",
    "    def load_image(self, index: int):\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path).convert('RGB'),image_path\n",
    "    \n",
    "    # 5. 覆盖 the __len__()方法 \n",
    "    def __len__(self) -> int:\n",
    "        \"返回样本总数\"\n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. 覆盖 __getitem__() 方法(作为torch.utils.data.Dataset子类必须重写该方法)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"根据index返回一个样本的data and label (X, y).\"\n",
    "        img,img_path = self.load_image(index)\n",
    "        writer_class_name  = img_path.name.split('_')[2] # 命名规则为: data_dir/word_font_writer_number.gif\n",
    "        writer_class_idx = self.writer_class_to_idx[writer_class_name]\n",
    "\n",
    "        # 对图片作转换\n",
    "        if self.transform:\n",
    "            return self.transform(img), writer_class_idx # 返回样本data, label (X, y)\n",
    "        else:\n",
    "            return img, writer_class_idx # 返回样本 data, label (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcef0bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对train data作转换\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    #transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 对test data只须统一shape并转换为Tensor\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bef2a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 实例化自定义的数据集对象，并拆分为训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "444c47bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataset.Subset at 0x29ddca278d0>,\n",
       " <torch.utils.data.dataset.Subset at 0x29ddca27eb8>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实例化自定义的数据集对象，并拆分为训练集和测试集\n",
    "data_custom = ImageFolderWordLibDataSet(targ_dir=IMAGE_PATH, \n",
    "                                        transform=train_transforms,\n",
    "                                        ext='gif')\n",
    "train_size=int(0.9*len(data_custom))\n",
    "test_size=len(data_custom)-train_size\n",
    "torch.manual_seed(42)\n",
    "train_dataset,test_dataset=torch.utils.data.random_split(data_custom,[train_size,test_size])\n",
    "\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa6f089e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5780, 5202, 578, 5780)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_custom),len(train_dataset),len(test_dataset),len(train_dataset)+len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "308a9576-835c-4eae-b002-2ba3ed0989d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataset.Subset at 0x29ddc876e80>,\n",
       " <torch.utils.data.dataset.Subset at 0x29ddc876198>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#实例化自定义的数据集对象，并拆分为训练集和测试集\n",
    "data_writer_custom = ImageWriterWordLibDataSet(targ_dir=IMAGE_PATH, \n",
    "                                        transform=train_transforms,\n",
    "                                        ext='gif')\n",
    "train_writer_size=int(0.9*len(data_writer_custom))\n",
    "test_writer_size=len(data_writer_custom)-train_writer_size\n",
    "torch.manual_seed(42)\n",
    "train_writer_dataset,test_writer_dataset=torch.utils.data.random_split(data_writer_custom,[train_writer_size,test_writer_size])\n",
    "\n",
    "train_writer_dataset, test_writer_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afc80f91-7a1c-4c96-bbe9-03380c786e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5780, 5202, 578, 5780)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_writer_custom),len(train_writer_dataset),len(test_writer_dataset),len(train_writer_dataset)+len(test_writer_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823232b2",
   "metadata": {},
   "source": [
    "###  创建随机显示图片的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f133b48b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. 输入参数为dataset、文字列表\n",
    "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
    "                          classes: List[str] = None,\n",
    "                          n: int = 10,\n",
    "                          display_shape: bool = True,\n",
    "                          seed: int = None):\n",
    "    \n",
    "    # 2. 为了好的显示效果，只允许显示10张\n",
    "    if n > 10:\n",
    "        n = 10\n",
    "        display_shape = False\n",
    "        print(f\"为了好的显示效果，最多只允许显示10张图片.\")\n",
    "    \n",
    "    # 3. 设置随机种子\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # 4. 获取抽样序号\n",
    "    random_samples_idx = random.sample(range(len(dataset)), k=n)\n",
    "\n",
    "    # 5. 设置figure大小\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    # 6. 显示每张抽取的图片\n",
    "    for i, targ_sample in enumerate(random_samples_idx):\n",
    "        targ_image, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
    "\n",
    "        # 7. 用permute函数调整image的tensor shape以正确显示图片:\n",
    "        # tensor的维度： [color_channels, height, width] -> 画图维度[height, width,color_channels]\n",
    "        targ_image_adjust = targ_image.permute(1, 2, 0) \n",
    "        if targ_image_adjust.shape[2]==1:\n",
    "            targ_image_adjust=targ_image_adjust.squeeze(2)  #如果图片只有1个通道，则需要压缩维度，去掉通道信息，否则不能正常显示\n",
    "        # 将n幅图画在1行\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(targ_image_adjust)\n",
    "        plt.axis(\"off\")\n",
    "        if classes:\n",
    "            title = f\"class: {classes[targ_label]}\"\n",
    "            if display_shape:\n",
    "                title = title + f\"\\nshape: {targ_image_adjust.shape}\"\n",
    "        plt.title(title,fontproperties='simhei')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b19bd11-6a0f-47c3-9281-4e7dcfe8f630",
   "metadata": {
    "tags": []
   },
   "source": [
    "display_random_images(train_dataset, \n",
    "                      n=18, \n",
    "                      classes=images_classes_list,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b16e0f7b-feea-4cbd-bc45-e444c805d411",
   "metadata": {},
   "source": [
    "display_random_images(train_writer_dataset, \n",
    "                      n=18, \n",
    "                      classes=images_writer_classes_list,\n",
    "                      seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202abf39",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  用 `DataLoader`来加载自定义的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e02b8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fce92ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x29ddc96e438>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x29ddc96e5c0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(dataset=train_dataset, # 使用自定义训练数据集\n",
    "                                     batch_size=32, # 每批次加载多少样本\n",
    "                                     num_workers=0, # 并行加载任务数 (越高越好，但不高于os.cpu_count(),0表示任务加载)\n",
    "                                     shuffle=True) # 是否乱序加载?\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset, # 使用自定义测试数据集\n",
    "                                    batch_size=32, \n",
    "                                    num_workers=0, \n",
    "                                    shuffle=False) # 不须乱序加载\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fca31c05-bcaf-43da-9322-e4b4e53a62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x29ddc96e4a8>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x29ddc96e5f8>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_writer_dataloader = DataLoader(dataset=train_writer_dataset, # 使用自定义训练数据集\n",
    "                                     batch_size=32, # 每批次加载多少样本\n",
    "                                     num_workers=0, # 并行加载任务数 (越高越好，但不高于os.cpu_count(),0表示任务加载)\n",
    "                                     shuffle=True) # 是否乱序加载?\n",
    "\n",
    "test_writer_dataloader = DataLoader(dataset=test_writer_dataset, # 使用自定义测试数据集\n",
    "                                    batch_size=32, \n",
    "                                    num_workers=0, \n",
    "                                    shuffle=False) # 不须乱序加载\n",
    "\n",
    "train_writer_dataloader, test_writer_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39372df1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([32, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n",
      "Label shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "# next一次加载一批\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df19878d-c5ea-4d14-b261-6d1323b39d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_writer shape: torch.Size([32, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n",
      "label_writer shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "img_writer, label_writer = next(iter(train_writer_dataloader))\n",
    "# next一次加载一批\n",
    "print(f\"img_writer shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"label_writer shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3662cbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    #transforms.TrivialAugmentWide(num_magnitude_bins=31,fill=255), # how intense \n",
    "    #transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "    #transforms.RandomRotation(degrees=(0, 180),expand=False,fill=255),\n",
    "    #transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.7, 0.9),fill=255),\n",
    "    #transforms.ElasticTransform(alpha=250.0,fill=255),\n",
    "    #transforms.RandomPerspective(distortion_scale=0.5, p=0.6,fill=255),\n",
    "    transforms.ToTensor() # use ToTensor() last to get everything between 0 & 1\n",
    "])\n",
    "\n",
    "# 对测试集不作增广变换\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)), \n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be97b4",
   "metadata": {},
   "source": [
    "###  创建TinyVGG模型类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4aeee66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=5120, out_features=483, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    卷积神经网络的模型参考了下面的结构，该网站详细解释了该结构，并对模型参数作了很好的可视化: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # 卷积核大小\n",
    "                      stride=1, # default\n",
    "                      padding=1), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            # 下面这一步的in_features设置有一定困难，如果维度计算不准，模型将报错，建议先把self.classifier这一层去掉，看前面结构的output_shape输出，\n",
    "            # 再根据这个输出确定这里的in_features\n",
    "            nn.Linear(in_features=hidden_units*16*16,out_features=output_shape) \n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # 这种用法效果相同且更高效\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model_0 = TinyVGG(input_shape=3, # 颜色通道 (3 for RGB) \n",
    "                  hidden_units=20, \n",
    "                  output_shape=len(images_classes_list)).to(device)\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bc59f3c-faf5-449f-b014-aa8f023cf1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'images_classes_list length is:{len(images_classes_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "069a546f-5429-4352-ab58-29ca9f0ff1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WriterTinyVGG(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=5120, out_features=447, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "class WriterTinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    卷积神经网络的模型参考了下面的结构，该网站详细解释了该结构，并对模型参数作了很好的可视化: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # 卷积核大小\n",
    "                      stride=1, # default\n",
    "                      padding=1), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            \n",
    "            # 下面这一步的in_features设置有一定困难，如果维度计算不准，模型将报错，建议先把self.classifier这一层去掉，看前面结构的output_shape输出，\n",
    "            # 再根据这个输出确定这里的in_features\n",
    "            nn.Linear(in_features=hidden_units*16*16,out_features=output_shape) \n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.conv_block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x\n",
    "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # 这种用法效果相同且更高效\n",
    "\n",
    "torch.manual_seed(42)\n",
    "writer_model_0 = WriterTinyVGG(input_shape=3, # 颜色通道 (3 for RGB) \n",
    "                  hidden_units=20, \n",
    "                  output_shape=len(images_writer_classes_list)).to(device)\n",
    "writer_model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc82f355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images_writer_classes_list length is:447\n"
     ]
    }
   ],
   "source": [
    "print(f'images_writer_classes_list length is:{len(images_writer_classes_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "020c021c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. 从test_dataloader中抽取一批数据用于显示\n",
    "itr=iter(test_dataloader)\n",
    "img_batch, label_batch= next(itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85859f2a-1319-43e6-aea5-00a9ae6923bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 从test_dataloader中抽取一批数据用于显示\n",
    "writer_itr=iter(test_writer_dataloader)\n",
    "img_writer_batch, label_writer_batch= next(writer_itr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9da22db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_from_image_tensor(img_tensor):\n",
    "    \"\"\"\n",
    "    把图片tensor显示成图片\n",
    "    \"\"\"\n",
    "    img =img_tensor.permute(1,2,0) #如果只想看某一个channel的话，再接上[:,:,0]\n",
    "    if img.shape[2]==1:\n",
    "        img=img.squeeze(2)\n",
    "    plt.imshow(img.cpu())  #对于在GPU上的数据集，需要调用.cpu()才能plot\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "993c3e1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def result_compare(iterator,model):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        image_batch, label_batch = next(iterator)\n",
    "        image_batch=image_batch.to(device)\n",
    "        pred_label=torch.argmax(model(image_batch),dim=1)\n",
    "        #print(model_0(image_batch).shape,pred_label,label_batch)\n",
    "        word_dict=dict()\n",
    "        label_dict=dict()         \n",
    "        fig, ax = plt.subplots(figsize=(12,6)) \n",
    "        ax.axis(False)\n",
    "        for i in range(len(label_batch)):\n",
    "            pred_word=images_classes_list[pred_label[i]]\n",
    "            word=images_classes_list[label_batch[i]]\n",
    "            ax = fig.add_subplot(4,8,i+1)\n",
    "            plot_from_image_tensor(image_batch[i])\n",
    "            word_dict[word] = pred_word\n",
    "            label_dict[label_batch[i]]=pred_label[i]\n",
    "            pred_compare=pd.DataFrame.from_dict(word_dict,orient='index')\n",
    "            pred_compare.reset_index(inplace=True)\n",
    "            pred_compare.columns=['实际汉字','识别结果']\n",
    "    return pred_compare"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88c8d235-9775-417a-9a11-99e88c5dfdcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "result=result_compare(itr,model_0)\n",
    "result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "009ac16f-1478-487a-bece-769fe4d98495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def writer_result_compare(iterator,model):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        image_writer_batch, label_writer_batch = next(iterator)\n",
    "        image_writer_batch=image_writer_batch.to(device)\n",
    "        pred_writer_label=torch.argmax(model(image_writer_batch),dim=1)\n",
    "        #print(model_0(image_batch).shape,pred_label,label_batch)\n",
    "        word_writer_dict=dict()\n",
    "        label_writer_dict=dict()         \n",
    "        fig, ax = plt.subplots(figsize=(12,6)) \n",
    "        ax.axis(False)\n",
    "        for i in range(len(label_writer_batch)):\n",
    "            pred_writer_word=images_writer_classes_list[pred_writer_label[i]]\n",
    "            word_writer=images_writer_classes_list[label_writer_batch[i]]\n",
    "            ax = fig.add_subplot(4,8,i+1)\n",
    "            plot_from_image_tensor(image_writer_batch[i])\n",
    "            word_writer_dict[word_writer] = pred_writer_word\n",
    "            label_writer_dict[label_writer_batch[i]]=pred_writer_label[i]\n",
    "            pred_compare=pd.DataFrame.from_dict(word_writer_dict,orient='index')\n",
    "            pred_compare.reset_index(inplace=True)\n",
    "            pred_compare.columns=['书写人','识别结果']\n",
    "    return pred_compare"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63c5da33-84ce-4f08-a4fe-67ab3a687aa3",
   "metadata": {},
   "source": [
    "writer_result=writer_result_compare(writer_itr,writer_model_0)\n",
    "writer_result.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efceaaef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 使用`torchinfo`来获得模型信息"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2e54fd9-7135-4b3c-978b-df5c39efd870",
   "metadata": {
    "tags": []
   },
   "source": [
    "# torchinfo这个包可以比较方便地显示模型结构和参数，如果import失败，需要安装\n",
    "try: \n",
    "    import torchinfo\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    import torchinfo\n",
    "    \n",
    "from torchinfo import summary\n",
    "summary(model_0, input_size=img_batch.shape) # summary函数非常方便，只需要把一个batch的shape作为输入就能够得模型信息，不须加载真实数据"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48730ebf-1a85-43fe-b1d3-5cf7cacbf75a",
   "metadata": {},
   "source": [
    "summary(writer_model_0, input_size=img_writer_batch.shape) # summary函数非常方便，只需要把一个batch的shape作为输入就能够得模型信息，不须加载真实数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e88f71",
   "metadata": {},
   "source": [
    "###  创建train_step和test_step函数\n",
    "主要定义了三个函数:\n",
    "1. `train_step()` - 输入参数为：model, `DataLoader`，loss function和optimizer\n",
    "2. `test_step()` - 输入参数为：model, `DataLoader`，loss function和optimizer\n",
    "3. `train()` - 定义train Loop，执行给定的epochs并返回一个结果集的dict.\n",
    "\n",
    "* 模型训练的标准流程：\n",
    "    * 0-上device\n",
    "    * 1-model(x)前向算结果\n",
    "    * 2-loss_fn根据结果算损失\n",
    "    * 3-zero_grad梯度全归零\n",
    "    * 4-backword反向传播算梯度\n",
    "    * 5-step更新参数    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b913830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # model进入训练模式\n",
    "    model.train()\n",
    "    \n",
    "    # 设置 train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # 对data loader的每个data批次进行训练。假如训练集有10000个数据，batch size为32的话，则有 (10000/32)=312.5经向上取整后共313个批次\n",
    "    # 但这不用手动计算，将dataloader放到enumerate()函数中会自动循环获取\n",
    "    # 有些代码也会使用iter(dataloader)进行循环，区别在于iter不会返回批次的序号\n",
    "    \n",
    "    # 0-5步为模型训练的标准流程：\n",
    "    '''\n",
    "    0-上device\n",
    "    1-前向算结果\n",
    "    2-根据结果算损失\n",
    "    3-zero_grad梯度全归零\n",
    "    4-backword反向传播算梯度\n",
    "    5-step更新参数\n",
    "    '''\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 0. 把数据放到目标device上\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X)\n",
    "\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()   #loss_fn返回的是tensor，调用.item()转换为numpy的值\n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # 6. Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
    "\n",
    "    # 计算每批次loss和accuracy的平均数\n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ae6640d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    # 开启test模式，有些dropout的层将跳过\n",
    "    model.eval() \n",
    "    \n",
    "    # 设置 test loss 和 test accuracy为0\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # 不会进行梯度计算，以加快运行速度\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Send data to target device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "    \n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(X)\n",
    "\n",
    "            # 2. Calculate and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, y)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
    "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    # 计算每个test batch平均损失和准确度\n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7e69a",
   "metadata": {},
   "source": [
    "### 创建训练Loop:将train_step()和test_step()放在train()函数中 \n",
    "\n",
    "1. 传入参数：model, 封装了训练集和测试集的`DataLoader`，优化器optimizer, 损失函数loss_fn，训练和测试的循环次数epochs\n",
    "2. 创建空的`train_loss`, `train_acc`, `test_loss` , `test_acc` 字典\n",
    "3. 对epoches中的每个epoch循环运行train()和test().\n",
    "4. 输出每个epoch的过程信息.\n",
    "5. 更新每个epoch的metrics字典.\n",
    "6. 返回结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0806cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. 定义train函数和传入参数\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5):\n",
    "    \n",
    "    # 2. 创建空字典用于存储结果\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Training循环\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. 输出结果\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. 更新结果字典\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # 6. 训练结束返回结果\n",
    "    return results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd2ce7b4-aff8-4833-953a-63561a60694c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# 设置epochs次数\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# 实例化模型\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=20, \n",
    "                  output_shape=len(data_custom.classes)).to(device)\n",
    "\n",
    "# 设置损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "\n",
    "# 用timer开始计时\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "# 开始训练模型model_0 \n",
    "model_0_results = train(model=model_0, \n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# 训练结束，输出训练时长\n",
    "end_time = timer()\n",
    "print(f\"训练时长: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8611f98e-d3df-40a1-88db-42bd8cacdf97",
   "metadata": {},
   "source": [
    "# 设置随机种子\n",
    "torch.manual_seed(42) \n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# 设置epochs次数\n",
    "NUM_EPOCHS =20\n",
    "\n",
    "# 实例化模型\n",
    "writer_model_0 = WriterTinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=20, \n",
    "                  output_shape=len(data_writer_custom.writer_classes)).to(device)\n",
    "\n",
    "# 设置损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=writer_model_0.parameters(), lr=0.001)\n",
    "\n",
    "# 用timer开始计时\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "# 开始训练模型model_0 \n",
    "writer_model_0_results = train(model=writer_model_0, \n",
    "                        train_dataloader=train_writer_dataloader,\n",
    "                        test_dataloader=test_writer_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=NUM_EPOCHS)\n",
    "\n",
    "# 训练结束，输出训练时长\n",
    "end_time = timer()\n",
    "print(f\"训练时长: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc5e2f1",
   "metadata": {},
   "source": [
    "### 查看预测结果"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79a5cab6-ad66-4c9b-8614-6be9220e42a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "model_0_df = pd.DataFrame(model_0_results) \n",
    "model_0_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb98a11b-19a7-4417-9125-05b976e0e068",
   "metadata": {},
   "source": [
    "writer_model_0_df = pd.DataFrame(writer_model_0_results) \n",
    "writer_model_0_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf51a75-d4c9-4d62-9647-0139309ecbea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 绘制训练过程曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5b342a0-5ed9-4ca7-98ca-609319fae3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_loss_curves(results: Dict[str, List[float]]):\n",
    "    \"\"\"绘制训练过程曲线.\n",
    "\n",
    "    Args:\n",
    "        results (dict): 训练过程记录dict,包括：\n",
    "            {\"train_loss\": [...],\n",
    "             \"train_acc\": [...],\n",
    "             \"test_loss\": [...],\n",
    "             \"test_acc\": [...]}\n",
    "    \"\"\"\n",
    "    \n",
    "    # 获取Train和test过程的loss值\n",
    "    loss = results['train_loss']\n",
    "    test_loss = results['test_loss']\n",
    "\n",
    "    # 获取train和test过程的准确度acc值\n",
    "    accuracy = results['train_acc']\n",
    "    test_accuracy = results['test_acc']\n",
    "\n",
    "    # 获取训练经历的epoches\n",
    "    epochs = range(len(results['train_loss']))\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label='train_loss')\n",
    "    plt.plot(epochs, test_loss, label='test_loss')\n",
    "    plt.title('Loss-损失', fontsize=16,fontproperties='Simhei')\n",
    "    plt.xlabel('Epochs-训练轮次', fontsize=16,fontproperties='Simhei')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label='train_accuracy-')\n",
    "    plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
    "    plt.title('Accuracy-准确度', fontsize=16,fontproperties='Simhei')\n",
    "    plt.xlabel('Epochs-训练轮次', fontsize=16,fontproperties='Simhei')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e52616d-b271-42d9-bc60-3371dcce478c",
   "metadata": {
    "tags": []
   },
   "source": [
    "result=result_compare(itr,model_0)\n",
    "result.T"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e49c96cb-d275-467e-9c5b-e25125da4452",
   "metadata": {
    "tags": []
   },
   "source": [
    "plot_loss_curves(model_0_results) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "12b79688-67d8-412d-92ea-cc0439d6d3bb",
   "metadata": {},
   "source": [
    "writer_result=writer_result_compare(writer_itr,writer_model_0)\n",
    "writer_result.T"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb497823-6f2c-42cc-9f5d-cbdba3a918d7",
   "metadata": {},
   "source": [
    "plot_loss_curves(writer_model_0_results) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b17d20",
   "metadata": {},
   "source": [
    "###  保存和加载训练好的模型\n",
    "* `torch.save` - 保存PyTorch模型或模型的参数`state_dict()`. \n",
    "* `torch.load` - 加载已保存的PyTorch对象.\n",
    "* `torch.nn.Module.load_state_dict()` - 加载通过保存的`state_dict()`模型参数到新的model实例中."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd4f719a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 创建用于保存模型的文件夹(如果已存在则不操作), see: https://docs.python.org/3/library/pathlib.html#pathlib.Path.mkdir\n",
    "MODEL_PATH = Path(\"data/models\")\n",
    "MODEL_PATH.mkdir(parents=True, #  \n",
    "                 exist_ok=True # 如果路径存在也不报错\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"CalligraphyRegTinyVGG.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "MODEL_WRITER_NAME = \"CalligraphyWriterRegTinyVGG.pth\"\n",
    "MODEL_WRITER_SAVE_PATH = MODEL_PATH / MODEL_WRITER_NAME\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e953b3a-4745-4575-a857-1018953f826c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 保存模型的state dict\n",
    "print(f\"Saving word regcognizer model to: {MODEL_SAVE_PATH}, word writer recognizer model to :{MODEL_WRITER_SAVE_PATH}\")\n",
    "\n",
    "torch.save(obj=model_0.state_dict(), # 只保存state_dict()中可学习的参数\n",
    "           f=MODEL_SAVE_PATH)\n",
    "torch.save(obj=writer_model_0.state_dict(), # 只保存state_dict()中可学习的参数\n",
    "           f=MODEL_WRITER_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfbe8b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建一个和保存的参数具有相同结构的模型实例，否则会报错\n",
    "model_0 = TinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=20, \n",
    "                  output_shape=len(data_custom.classes))\n",
    "# 加载state_dict()\n",
    "model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH,map_location=torch.device(device)))\n",
    "\n",
    "# 将模型发送到相应的device\n",
    "model_0 = model_0.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb3a4cd0-f3e9-40b7-944c-dca35b2e5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个和保存的参数具有相同结构的模型实例，否则会报错\n",
    "writer_model_0 = WriterTinyVGG(input_shape=3, # number of color channels (3 for RGB) \n",
    "                  hidden_units=20, \n",
    "                  output_shape=len(data_writer_custom.writer_classes))\n",
    "# 加载state_dict()\n",
    "writer_model_0.load_state_dict(torch.load(f=MODEL_WRITER_SAVE_PATH,map_location=torch.device(device)))\n",
    "\n",
    "# 将模型发送到相应的device\n",
    "writer_model_0 = writer_model_0.to(device)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9ee24de-0e6c-4ade-b0f4-e850e5d553c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(type(model_0.state_dict()))  # 查看state_dict所返回的类型，是一个“顺序字典OrderedDict”\n",
    " \n",
    "for param_tensor in model_0.state_dict(): # 字典的遍历默认是遍历 key，所以param_tensor实际上是键值\n",
    "    print(param_tensor,'\\t',model_0.state_dict()[param_tensor].shape) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "b27e30e3-304c-4610-a26d-7b51f78da9eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "for i,param in enumerate(model_0.parameters()):\n",
    "    print(i,param.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7de6824-4a0b-4b17-9453-ce23234455db",
   "metadata": {},
   "source": [
    "print(type(writer_model_0.state_dict()))  # 查看state_dict所返回的类型，是一个“顺序字典OrderedDict”\n",
    " \n",
    "for param_tensor in writer_model_0.state_dict(): # 字典的遍历默认是遍历 key，所以param_tensor实际上是键值\n",
    "    print(param_tensor,'\\t',writer_model_0.state_dict()[param_tensor].shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066e57a",
   "metadata": {},
   "source": [
    "### 使用预训练模型作预测"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b8ee56c-87ad-420f-bbb0-7c41f99d7e69",
   "metadata": {
    "tags": []
   },
   "source": [
    "result=result_compare(itr,loaded_model_0)\n",
    "result.T"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f08a708-e69e-4325-8ae6-7a2d84d73225",
   "metadata": {},
   "source": [
    "writer_result=writer_result_compare(writer_itr,loaded_writer_model_0)\n",
    "writer_result.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7480f21e-16e8-4aab-ad60-cd69d59846fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_by_file_name(image_path,show=True)->(str,str,Image):\n",
    "    \n",
    "    '''\n",
    "    定义函数 get_image_by_file_name，根据图片文件名返回图片内容，并显示该图片\n",
    "    Args:\n",
    "        image_path (str): 文字图片路径和文件名.\n",
    "        show (Boolean): 是否显示文字图片\n",
    "\n",
    "    Returns:\n",
    "        img:图片内容\n",
    "\n",
    "    Example:\n",
    "        data\\wordlib\\予_行书_鲜于枢_12046.gif \"_\"前面的字符是书法对应的文字\n",
    "        \n",
    "    '''  \n",
    "    print(image_path)\n",
    "    img=Image.open(image_path).convert('RGB')  #    丁_草书_王铎_131029.gif data/wordlib/zxqsig.jpg\n",
    "    if show:\n",
    "            plt.figure(figsize=(2, 2)) \n",
    "            plt.imshow(img)  \n",
    "            plt.title(f\"图片size(H,W)为:({img.height}, {img.width})\",fontsize=16,fontproperties='Simhei')\n",
    "            plt.axis(False)    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7de6ec57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_by_image_name(image_path,model):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        query_image=get_image_by_file_name(image_path,show=True)        \n",
    "        img=test_transforms(query_image).unsqueeze(0).to(device)\n",
    "        pred_label=torch.argmax(model(img),dim=1)        \n",
    "        print(f'\\n图片文字预测为:\\\"{images_classes_list[pred_label]}\\\"，其Label为{pred_label.item()}')\n",
    "    return images_classes_list[pred_label], pred_label.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20b3749a-2b12-4cfa-bb65-60bac7d3942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_writer_by_image_name(image_path,model):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        query_image=get_image_by_file_name(image_path,show=True)        \n",
    "        img=test_transforms(query_image).unsqueeze(0).to(device)\n",
    "        pred_label=torch.argmax(model(img),dim=1)        \n",
    "        print(f'\\n图片文字预测为:\\\"{images_writer_classes_list[pred_label]}\\\"，其Label为{pred_label.item()}')\n",
    "    return images_writer_classes_list[pred_label], pred_label.item()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b91d6203-9727-48d2-8bb5-f6b445b8769c",
   "metadata": {
    "tags": []
   },
   "source": [
    "predict_writer_by_image_name(r'data\\wordlib\\擬_行书_苏轼_31314.gif',loaded_writer_model_0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
